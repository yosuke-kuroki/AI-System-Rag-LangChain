{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "authorship_tag": "ABX9TyOqYbvDNzj8MP7+jk33hT3j"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **AI Agents and Assistants**\n",
    "\n",
    "Technology Used:\n",
    "\n",
    "![Python](https://img.shields.io/badge/python-v3.7+-blue.svg)\n",
    "![Jupyter](https://img.shields.io/badge/jupyter-v1.0+-blue.svg)\n",
    "![CrewAI](https://img.shields.io/badge/crewai-v0.0.1-blue.svg)\n",
    "![DuckDuckGo](https://img.shields.io/badge/duckduckgo_search-v0.0.1-blue.svg)\n",
    "![OpenAI](https://img.shields.io/badge/openai-v0.0.1-blue.svg)\n",
    "![Google Colab](https://img.shields.io/badge/google_colab-v1.0+-blue.svg)"
   ],
   "metadata": {
    "id": "C1lOmkl7-Aad"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **1. AI Agents**\n",
    "\n",
    "<img src=\"https://mapxp.app/MBA742/AI_agent.png\" width=\"900\"/>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "--------\n",
    "<br><br>"
   ],
   "metadata": {
    "id": "tuzOHBEjBQAn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://mapxp.app/MBA742/AI_agent_email.png\" width=\"900\"/>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "--------\n",
    "<br><br>"
   ],
   "metadata": {
    "id": "0SQXhiiMHYjb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<img src=\"https://mapxp.app/MBA742/AI_agent_productivity.png\" width=\"900\"/>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "--------\n",
    "<br><br>"
   ],
   "metadata": {
    "id": "fcWK_bJ_HYmE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://mapxp.app/MBA742/AI_agent_humans.png\" width=\"900\"/>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "--------\n",
    "<br><br>"
   ],
   "metadata": {
    "id": "4uC6smIvHYpD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://mapxp.app/MBA742/AI_agent_chatbots.png\" width=\"900\"/>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "--------\n",
    "<br><br>"
   ],
   "metadata": {
    "id": "RbaK8qZtHYri"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://mapxp.app/MBA742/AI_agent_platforms.png\" width=\"900\"/>\n",
    "\n",
    "<br><br>"
   ],
   "metadata": {
    "id": "14LAbE8tIQ53"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **2. Building an AI Agent with CrewAI**\n",
    "\n",
    "https://www.crewai.com/open-source\n",
    "\n",
    "**Objective:** Automate writing a LinkedIn post on a topic of interest.  \n",
    "\n",
    "**Requirements:**\n",
    "* Contemporary Data\n",
    "* Relevant Insights\n",
    "* Text in the style and format of a LinkedIn post\n",
    "\n",
    "**Approach:**\n",
    "1. Collect data on topic of interest\n",
    "2. Synthetsize collected data\n",
    "3. Extract key insights and messages\n",
    "4. Create a post suitable for LinkedIn"
   ],
   "metadata": {
    "id": "yr-973iE8FaR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **2.1 Install and Import Libraries**"
   ],
   "metadata": {
    "id": "F7E2b7TgJvuP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Install missing Libraries and Packages ---\n",
    "!sudo apt-get update\n",
    "!pip install --q crewai\n",
    "!pip install --q 'crewai[tools]'\n",
    "!pip install -U duckduckgo_search"
   ],
   "metadata": {
    "id": "dKwYr6OkBTHj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Import all Libraries and Packages ---\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "from crewai import Agent, Task, Process, Crew, LLM\n",
    "from crewai_tools import ScrapeWebsiteTool\n",
    "from crewai.tools import tool\n",
    "\n",
    "from duckduckgo_search import DDGS\n",
    "import re"
   ],
   "metadata": {
    "id": "cJ9YzKvZKUdZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## **2.2 What is your Agent Researching?**",
   "metadata": {
    "id": "SAdr2idpJ4Vy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Define Research Topic ---\n",
    "research_topic = \"the future of a computer science degree in the age of AI\""
   ],
   "metadata": {
    "id": "EY6X-rlM7S0h"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **2.3 Select LLMs and other Tools**\n",
    "\n",
    "* Need genAI for insight extraction and writing\n",
    "* Need to find content on the web\n",
    "* Need to scrape (download) content from the web"
   ],
   "metadata": {
    "id": "ohzH8WV-LTaN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Set API Key ---\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "# --- Configure genAI Models ---\n",
    "llm = LLM(\n",
    "    model=\"gpt-4o\",\n",
    "    # temperature=0.7,\n",
    "    # timeout=120,\n",
    "    # max_tokens=4000,\n",
    "    # top_p=0.9,\n",
    "    # frequency_penalty=0.1,\n",
    "    # presence_penalty=0.1,\n",
    "    # seed=42\n",
    ")\n",
    "\n",
    "llm_reason = LLM(\n",
    "    model=\"o1-mini\"\n",
    ")"
   ],
   "metadata": {
    "id": "8UkZcUcu6_i6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Set-up Tools ---\n",
    "\n",
    "# Tool 1 : Search for relevant Webpages\n",
    "@tool\n",
    "def duckduckgo_URLs(search_query: str):\n",
    "    \"\"\"Wrapper for crewai around duckduckgo_search: Searches the web using DuckDuckGo and returns a summary of findings.\"\"\"\n",
    "    results = DDGS().text(search_query, max_results=5)\n",
    "    urls = []\n",
    "    for result in results:\n",
    "      if 'href' in result:\n",
    "        url = result['href']\n",
    "        urls.append(url)\n",
    "    return urls\n",
    "\n",
    "# Tool 2 : CrewAI internal tool: Scrapes webpages\n",
    "read_webpage = ScrapeWebsiteTool()"
   ],
   "metadata": {
    "id": "VCNrrM0b7G1k"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **2.4 Design your Agents**"
   ],
   "metadata": {
    "id": "7A0jp7BSLnNX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Define Agents ---\n",
    "researcher = Agent(\n",
    "    role=\"Senior Researcher\",\n",
    "    goal=f\"Find the most relevant webpages for {research_topic} using DuckDuckGo.\",\n",
    "    backstory=\"An expert in online research, capable of identifying the most relevant webpages for a given topic.\",\n",
    "    llm=llm,\n",
    "    tools=[duckduckgo_URLs]\n",
    ")\n",
    "\n",
    "analyst = Agent(\n",
    "    role=\"Senior Analyst\",\n",
    "    goal=f\"Find the most relevant content on {research_topic} on a webpage.\",\n",
    "    backstory=\"An expert in extracting relevant information from webpages. \\\n",
    "              Documents and includes all relevant sources (including URL) to each piece of information\",\n",
    "    llm=llm,\n",
    "    #llm=llm_reason,\n",
    "    tools=[read_webpage]\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "    role=\"Experienced Journalist\",\n",
    "    goal=\"Write a well-structured and engaging report based on the research findings. \\\n",
    "          Make sure to cite relevant sources (including URL) for all claims and statements.\",\n",
    "    backstory=\"A skilled writer specializing in translating complex information into clear and understandable language.\",\n",
    "    llm=llm\n",
    "    #llm=llm_reason\n",
    ")\n",
    "\n",
    "blogger = Agent(\n",
    "    role=\"Expert Blogger\",\n",
    "    goal=\"Write a compact and compelling LinkedIn post in typical languge.\\\n",
    "          Use emojis and include relevant hashtags #. \\\n",
    "          Refer to people, firms and organizations with mentions @ .\",\n",
    "    backstory=\"A social media expert and successful blogger who has thousands of followers on LinkedIn \\\n",
    "              and knows how to write engaging posts.\",\n",
    "    llm=llm\n",
    ")"
   ],
   "metadata": {
    "id": "ls2jCsrd7Vng"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **2.5 Define Tasks for Agents**"
   ],
   "metadata": {
    "id": "qoqKZRCBLuLP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Define Tasks ---\n",
    "research_task = Task(\n",
    "    description=f\"Use DuckDuckGo to find webpages with latest trends and news from 2024 and 2025 on {research_topic}.\",\n",
    "    expected_output=\"A list of relevant URLs\",\n",
    "    agent=researcher\n",
    ")\n",
    "\n",
    "extraction_task = Task(\n",
    "    description=f\"Visit each webpage and extract the most relevant insights on {research_topic}\",\n",
    "    expected_output=f\"A well-structured narrative of key insights, each citing supporting sources.\",\n",
    "    agent=analyst,\n",
    "    context=[research_task]\n",
    ")\n",
    "\n",
    "writing_task = Task(\n",
    "    description=\"Transform the insights into a punchy executive summary with a call to action.\",\n",
    "    expected_output=\"A well-structured and engaging executive summary with clear action points. \\\n",
    "                    All sources at the bottom under *References*, including their URL.\",\n",
    "    agent=writer,\n",
    "    context=[extraction_task]\n",
    ")\n",
    "\n",
    "post_task = Task(\n",
    "    description=\"Translate the executive summary into an engaging and thought-provoking LinkedIn post.\",\n",
    "    expected_output=\"A polished LinkedIn post with no more than 200 words that provokes comments and likes.\",\n",
    "    agent=blogger,\n",
    "    context=[writing_task]\n",
    ")"
   ],
   "metadata": {
    "id": "hjj8Ey5LDQlL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **2.6 Define a Workflow**\n",
    "\n",
    "* Involved Agents\n",
    "* Tasks\n",
    "* Process"
   ],
   "metadata": {
    "id": "UT2bhg16L0E3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Define and Run Crew Process ---\n",
    "LinkedIn_crew = Crew(\n",
    "    agents=[researcher, analyst, writer, blogger],\n",
    "    tasks=[research_task, extraction_task, writing_task, post_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=True # set to false if you don't want to see the crew work\n",
    ")"
   ],
   "metadata": {
    "id": "nFcwzaPg7cQw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **2.7 Launch your Agents**"
   ],
   "metadata": {
    "id": "DxjPeUSZMAeZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ---  Put your AI Agent Crew to work ---\n",
    "results = LinkedIn_crew.kickoff()\n",
    "print(\"âœ… Your crew has finished their work.\")"
   ],
   "metadata": {
    "id": "ONhOzDGM7nMa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **2.8 Examine Results**"
   ],
   "metadata": {
    "id": "0vb73608MGkM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ---  Check out your AI Crew's Work ---\n",
    "print(results)"
   ],
   "metadata": {
    "id": "PjJBachM2EfN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ---  See how we got there: Extract all task outputs ---\n",
    "for task in results.tasks_output:\n",
    "    print(f\"\\nðŸ”¹ Task: {task.description}\")\n",
    "    print(f\"ðŸ‘¤ Performed by: {task.agent}\")\n",
    "    print(f\"ðŸ“Œ Expected Output: {task.expected_output}\")\n",
    "    print(f\"ðŸ“œ Generated Output:\\n\\n{task.raw}\\n\")"
   ],
   "metadata": {
    "id": "Fqno50q5qhia"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **3. An Agentic World**\n",
    "\n",
    "<img src=\"https://mapxp.app/MBA742/AI_agent_lives.png\" width=\"900\"/>\n",
    "\n",
    "<br><br>"
   ],
   "metadata": {
    "id": "gVoCyOk-IhM6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. AI Cloaking: Techniques and Implications\n",
    "\n",
    "**AI Cloaking** refers to strategies designed to make AI-generated content indistinguishable from human-generated content. In the context of AI agents and content creation, cloaking can help:\n",
    "- **Enhance Credibility:**\n",
    "  - By refining language and style, AI-generated text appears more natural, reducing the risk of detection as machine-produced.\n",
    "- **Improve User Engagement:**\n",
    "  - Cloaked content better resonates with audiences who expect authentic, human-like communication.\n",
    "- **Mitigate Ethical and Privacy Concerns:**\n",
    "  - In some contexts, it is beneficial to hide the origin of the content to protect proprietary processes or comply with privacy guidelines.\n",
    "\n",
    "### Techniques for AI Cloaking\n",
    "1. **Style Mimicry:**\n",
    "   - Adjust model parameters (such as temperature, frequency, and presence penalties) to fine-tune the tone and style of the generated text.\n",
    "   - Use human feedback loops to refine and \"humanize\" the language.\n",
    "\n",
    "2. **Post-Processing Filters:**\n",
    "   - Apply linguistic filters and natural language processing (NLP) techniques to remove common artifacts of AI generation (e.g., repetitive phrasing or overly formal language).\n",
    "   - Introduce variability in sentence structure and word choice to mimic human idiosyncrasies.\n",
    "\n",
    "3. **Contextual Embedding:**\n",
    "   - Incorporate contextual details that are typical of human authorship, such as personal anecdotes or references to current events, to enrich the narrative.\n",
    "\n",
    "4. **Hybrid Generation Approaches:**\n",
    "   - Combine human editing with AI-generated drafts to create a final output that leverages the strengths of both.\n",
    "   - Use AI for the heavy lifting of research and synthesis, then have human oversight for style and tone adjustments.\n",
    "\n",
    "### Implications of AI Cloaking\n",
    "- **For Business:**\n",
    "  - Enables the seamless integration of AI-generated content into corporate communications, marketing, and strategic messaging.\n",
    "- **For Research:**\n",
    "  - Provides a tool for generating high-quality, indistinguishable content that can be used in experiments or case studies.\n",
    "- **For Ethics:**\n",
    "  - Raises important questions about transparency and the ethical use of AI, making it critical to consider when and how cloaking should be employed.\n",
    "\n",
    "<img src=\"https://mapxp.app/MBA742/AI_agent_cloaking.png\" width=\"900\"/>\n"
   ],
   "metadata": {
    "id": "TZiO6JAoIwRk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Export this notebook to markdown\n",
    "\n",
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Convert to markdown: make sure that your path and filename are correct\n",
    "!jupyter nbconvert --to markdown \"/content/drive/MyDrive/488/Class11/488_2025_Class11.ipynb\"\n",
    "\n",
    "# download file: make sure that your path and filename are correct and consistent with those above\n",
    "files.download(\"/content/drive/MyDrive/488/Class11/488_2025_Class11.md\")"
   ],
   "metadata": {
    "id": "SYLWHw79DdXE"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
